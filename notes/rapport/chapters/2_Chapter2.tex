\chapter{Previous Work}

Image stylization has been around for years. Algorithms were created to automatise this desire to stylize. Some techniques use line extraction algorithm to then use convolution of points to make hand drawing styles. Hertzmann with his \textit{curve stroke} algorithm \cite{rosin_stroke_2013}  succeed to create images that look like a traditional painting with paintbrushes. To do so he computes many control pint on the original image to further place strokes. But these create a problem when we wanted to stylize videos because it treats frames independantly and so it creates bad \textit{motion continuity}. The movie \textit{Loving Vincent}\cite{LovingVincent} can illustrate what can happen in this case of bad \textit{motion continuity}.

Then some researches have be to propose a solution to this issue\cite{litwinowicz_processing_1997, hays_image_2004, bousseau_video_2007, lin_video_nodate}. The solution of Lin et \textit{al.} \cite{lin_video_nodate} is to create a segmentation manually of each key frame and then for each part of this segmentation they compute the motion. With this motion they adapt the stroke based rendering of the next frames. To have a watercolor stylization on a video Bousseau et \textit{al.} compute a texture advection to apply to the final image the wanted effect.

In our approach, the goal is to make stylized rendering of 3D objects. There are two moments in a pipeline rendering when we can stylize an object, the first is when we manipulate the vertices and the color of each triangle it is the \textit{object space}. The second is when we do the compositing with the textures that we have like shadow map, image filter, ... (manipulation of pixels of the screen) it is the \textit{image space} and also called \textit{screen space}.
