\chapter{Previous Work}

Image stylization has been around for years. Researchers first start to stylize images \cite{litwinowicz_processing_1997, hays_image_2004, rosin_stroke_2013, zeng_image_2009, kyprianidis_image_2009, lu_interactive_2010, litwinowicz_processing_1997, kyprianidis_state_2013} in order to have non-photorealistic images. Then they tried to stylize video\cite{lin_video_nodate, litwinowicz_processing_1997, kyprianidis_state_2013, bousseau_video_2007} some of them use the advantage to have the motion flow to improve the \textit{temporal coherence}. In our approach, we want to stylize 3D object. The advantages of it is that we have more information (like the position of each vertices, the normals, the distance from the camera, ...) about the scene than just an image or a video. In our approach, the goal is to make stylized rendering of 3D objects. There are two moments in a pipeline rendering when we can stylize an object, the first is when we manipulate the vertices and the color of each triangle it is the \textit{object space}. The second is when we do the compositing with the textures that we have like shadow map, image filter, ... (manipulation of pixels of the screen) it is the \textit{image space} and also called \textit{screen space}

\section{Object Space}

% texture based

\textbf{Texture based methods}

One of the most used ways to colored object in 3D is the \textit{texture mapping} \cite{texture_mapping}. It consists to add information to each vertex of the 3D object. These information many times are 2D coordinates that correspond to the position of a pixel in a 2D texture. This technique is very used in video games because it is easy to implement, it can be implemented for GPU and it needs low computation. Cel-shading, toon art mapping , gooch shading and others\cite{benard_state---art_2011} are texture based rendering in object space\cite{praun_real-time_2001, klein_non-photorealistic_2000, benard_dynamic_2009, benard_dynamic_2010, freudenberg_walk-through_2001} which are used to stylize scene. As said by Bénard et \textit{al.} \cite{benard_dynamic_2009} textures naturally ensure \textit{motion coherence} and \textit{temporal continuity}. Indeed because each vertex has his color and so the color in moving with the object but gives a bad \textit{flatness} because if the object gets bigger and bigger, pixelization will appear. In order to solve this problem some\cite{klein_non-photorealistic_2000, benard_dynamic_2009} tries to use mipmaps (combining multiple scales of textures) to improve \textit{flatness}. Bénard et \textit{al.}\cite{benard_dynamic_2010} use the same principle but with procedural textures. They create multiple noises with different frequency and combine them playing with transparency. Moreover, they overlap the noise to make an impression of infinite zoom effect (like in this example: \href{https://www.shadertoy.com/view/XlBXWw?fbclid=IwAR1fU2JxQzXtks1ZcmVmzrHiv646G8w2gWceeiV-UToeFkAFMQ2NecbsGGs}{ShaderToy}). With this method patterns of the texture have an almost constant size regardless of the size of the object but it can create small problem of \textit{temporal continuity}. In our method we will use this technique of fractalization of a procedural noise.



\textbf{Mark based methods}

The natural way to stylize 3D objects is to as an artist apply paint strokes on the object. These paint strokes can be represented with smalls images also called splats. Daniels\cite{Daniels_1999} and Schmid\cite{schmid_overcoat} propose to project splats composed of stroke and stored them on the geometry of the model but this technique is expensive in term of storage. Some works \cite{meier_painterly_1996, Fekete_2000, chi_stylized_2006}(more in the state of the art \cite{benard_state---art_2011}) use point distribution in order to make anchor points for splats. These point distributions are often compute in image space and then are projected on the model. Anchor these splats to the model improve the \textit{motion coherence} because each splat will follow the motion of the 3D model. These splats are rendered in the image space as a 2D sprites so preserved the \textit{flatness}. The problem is how to have the point distribution and how can we control it in order to have an uniform, not too sparse and not too dense distribution. Moreover these point distribution does not provide control on the \textit{temporal continuity}. In our method we use procedural noise to anchor the splats.


\section{Image space}

\textbf{Texture based methods}

Many method to stylize in image space used texture based approaches. It consists to apply the texture to the entire image \cite{benard_state---art_2011} but in the case in stylizing animated scenes the problem is how do we deform the texture to minimize the apparition of sliding artifiacts. We can distinguished two families of approaches to solve this problem. The first family of approaches use approximation of the 3D camera motion with 2D transformations of the texture\cite{cunzi_dynamic_nodate}. This gives a nice trade-off between \textit{motion coherence} and \textit{flatness} but it is limited to static scene and a set of few camera motions. Moreover sliding artifacts still occur with strong parallax so Fung et al.\cite{fung_pen-and-ink_nodate} and Breslav et al.\cite{breslav_dynamic_nodate} improve the approximation of the scene motion in order to reduce sliding artifacts.

The second family of approaches use non-rigid deformations to animate the texture\cite{bousseau_video_2007}. These deformations are computed from the optical flow of a video. This is an extension of the methods used in vector field visualization by Neyret\cite{neyret_imagis-gravir_nodate}. These deformations can distort the texture and alter the original pattern. The method of Bousseau et al.\cite{bousseau_video_2007} is very effective with stochastic textures as the fractalization process but creates artifacts with structured patterns.



\textbf{Mark based methods}
