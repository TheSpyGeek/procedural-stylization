
@article{benard_state---art_2011,
	title = {State-of-the-{Art} {Report} on {Temporal} {Coherence} for {Stylized} {Animations}},
	volume = {30},
	issn = {01677055},
	url = {http://doi.wiley.com/10.1111/j.1467-8659.2011.02075.x},
	doi = {10.1111/j.1467-8659.2011.02075.x},
	abstract = {Non-photorealistic rendering (NPR) algorithms allow the creation of images in a variety of styles, ranging from line drawing and pen-and-ink to oil painting and watercolor. These algorithms provide greater ﬂexibility, control and automation over traditional drawing and painting. Despite signiﬁcant progress over the past 15 years, the application of NPR to the generation of stylized animations remains an active area of research. The main challenge of computer generated stylized animations is to reproduce the look of traditional drawings and paintings while minimizing distracting ﬂickering and sliding artifacts present in hand-drawn animations. These goals are inherently conﬂicting and any attempt to address the temporal coherence of stylized animations is a trade-off. This state-of-the-art report is motivated by the growing number of methods proposed in recent years and the need for a comprehensive analysis of the trade-offs they propose. We formalize the problem of temporal coherence in terms of goals and compare existing methods accordingly. We propose an analysis for both line and region stylization methods and discuss initial steps toward their perceptual evaluation. The goal of our report is to help uninformed readers to choose the method that best suits their needs, as well as motivate further research to address the limitations of existing methods.},
	language = {en},
	number = {8},
	urldate = {2019-02-05},
	journal = {Computer Graphics Forum},
	author = {Bénard, Pierre and Bousseau, Adrien and Thollot, Joëlle},
	month = dec,
	year = {2011},
	pages = {2367--2386},
	file = {Bénard et al. - 2011 - State-of-the-Art Report on Temporal Coherence for .pdf:/home/misnel/Zotero/storage/C2AS7BK3/Bénard et al. - 2011 - State-of-the-Art Report on Temporal Coherence for .pdf:application/pdf}
}

@inproceedings{bleron_motion-coherent_2018,
	address = {Victoria, British Columbia, Canada},
	title = {Motion-coherent stylization with screen-space image filters},
	isbn = {978-1-4503-5892-7},
	url = {http://dl.acm.org/citation.cfm?doid=3229147.3229163},
	doi = {10.1145/3229147.3229163},
	language = {en},
	urldate = {2019-02-06},
	booktitle = {Proceedings of the {Joint} {Symposium} on {Computational} {Aesthetics} and {Sketch}-{Based} {Interfaces} and {Modeling} and {Non}-{Photorealistic} {Animation} and {Rendering}  - {Expressive} '18},
	publisher = {ACM Press},
	author = {Bléron, Alexandre and Vergne, Romain and Hurtut, Thomas and Thollot, Joëlle},
	year = {2018},
	pages = {1--13},
	file = {Bléron et al. - 2018 - Motion-coherent stylization with screen-space imag.pdf:/home/misnel/Zotero/storage/L4CI7SKX/Bléron et al. - 2018 - Motion-coherent stylization with screen-space imag.pdf:application/pdf}
}

@inproceedings{perlin_improving_2002,
	address = {New York, NY, USA},
	series = {{SIGGRAPH} '02},
	title = {Improving {Noise}},
	isbn = {978-1-58113-521-3},
	url = {http://doi.acm.org/10.1145/566570.566636},
	doi = {10.1145/566570.566636},
	abstract = {Two deficiencies in the original Noise algorithm are corrected: second order interpolation discontinuity and unoptimal gradient computation. With these defects corrected, Noise both looks better and runs faster. The latter change also makes it easier to define a uniform mathematical reference standard.},
	urldate = {2019-02-06},
	booktitle = {Proceedings of the 29th {Annual} {Conference} on {Computer} {Graphics} and {Interactive} {Techniques}},
	publisher = {ACM},
	author = {Perlin, Ken},
	year = {2002},
	note = {event-place: San Antonio, Texas},
	keywords = {procedural, texture},
	pages = {681--682},
	file = {ACM Full Text PDF:/home/misnel/Zotero/storage/NB7C3IKE/Perlin - 2002 - Improving Noise.pdf:application/pdf}
}

@article{noauthor_anintroductiontostylizedrendering_nodate,
	title = {{AnIntroductionToStylizedRendering}},
	language = {en},
	pages = {25},
	file = {AnIntroductionToStylizedRendering.pdf:/home/misnel/Zotero/storage/2NHYF372/AnIntroductionToStylizedRendering.pdf:application/pdf}
}

@inproceedings{schmid_overcoat:_2011,
	address = {Vancouver, British Columbia, Canada},
	title = {{OverCoat}: an implicit canvas for 3D painting},
	isbn = {978-1-4503-0943-1},
	shorttitle = {{OverCoat}},
	url = {http://portal.acm.org/citation.cfm?doid=1964921.1964923},
	doi = {10.1145/1964921.1964923},
	abstract = {We present a technique to generalize the 2D painting metaphor to 3D that allows the artist to treat the full 3D space as a canvas. Strokes painted in the 2D viewport window must be embedded in 3D space in a way that gives creative freedom to the artist while maintaining an acceptable level of controllability. We address this challenge by proposing a canvas concept deﬁned implicitly by a 3D scalar ﬁeld. The artist shapes the implicit canvas by creating approximate 3D proxy geometry. An optimization procedure is then used to embed painted strokes in space by satisfying different objective criteria deﬁned on the scalar ﬁeld. This functionality allows us to implement tools for painting along level set surfaces or across different level sets. Our method gives the power of ﬁne-tuning the implicit canvas to the artist using a uniﬁed painting/sculpting metaphor. A sculpting tool can be used to paint into the implicit canvas. Rather than adding color, this tool creates a local change in the scalar ﬁeld that results in outward or inward protrusions along the ﬁeld’s gradient direction. We address a visibility ambiguity inherent in 3D stroke rendering with a depth offsetting method that is well suited for hardware acceleration. We demonstrate results with a number of 3D paintings that exhibit effects difﬁcult to realize with existing systems.},
	language = {en},
	urldate = {2019-02-07},
	booktitle = {{ACM} {SIGGRAPH} 2011 papers on - {SIGGRAPH} '11},
	publisher = {ACM Press},
	author = {Schmid, Johannes and Senn, Martin Sebastian and Gross, Markus and Sumner, Robert W.},
	year = {2011},
	pages = {1},
	file = {Schmid et al. - 2011 - OverCoat an implicit canvas for 3D painting.pdf:/home/misnel/Zotero/storage/6RKV89GP/Schmid et al. - 2011 - OverCoat an implicit canvas for 3D painting.pdf:application/pdf}
}

@inproceedings{montesdeoca_mnpr:_2018,
	address = {Victoria, British Columbia, Canada},
	title = {{MNPR}: a framework for real-time expressive non-photorealistic rendering of 3D computer graphics},
	isbn = {978-1-4503-5892-7},
	shorttitle = {{MNPR}},
	url = {http://dl.acm.org/citation.cfm?doid=3229147.3229162},
	doi = {10.1145/3229147.3229162},
	abstract = {We propose a framework for expressive non-photorealistic rendering of 3D computer graphics: MNPR. Our work focuses on enabling stylization pipelines with a wide range of control, thereby covering the interaction spectrum with real-time feedback. In addition, we introduce control semantics that allow cross-stylistic art-direction, which is demonstrated through our implemented watercolor, oil and charcoal stylizations. Our generalized control semantics and their style-speci c mappings are designed to be extrapolated to other styles, by adhering to the same control scheme. We then share our implementation details by breaking down our framework and elaborating on its inner workings. Finally, we evaluate the usefulness of each level of control through a user study involving 20 experienced artists and engineers in the industry, who have collectively spent over 245 hours using our system. MNPR is implemented in Autodesk®Maya®and open-sourced through this publication, to facilitate adoption by artists and further development by the expressive research and development community.},
	language = {en},
	urldate = {2019-02-11},
	booktitle = {Proceedings of the {Joint} {Symposium} on {Computational} {Aesthetics} and {Sketch}-{Based} {Interfaces} and {Modeling} and {Non}-{Photorealistic} {Animation} and {Rendering}  - {Expressive} '18},
	publisher = {ACM Press},
	author = {Montesdeoca, Santiago E. and Seah, Hock Soon and Semmo, Amir and Bénard, Pierre and Vergne, Romain and Thollot, Joëlle and Benvenuti, Davide},
	year = {2018},
	pages = {1--11},
	file = {Montesdeoca et al. - 2018 - MNPR a framework for real-time expressive non-pho.pdf:/home/misnel/Zotero/storage/35HQAVYB/Montesdeoca et al. - 2018 - MNPR a framework for real-time expressive non-pho.pdf:application/pdf}
}

@article{benard_active_2012,
	title = {Active {Strokes}: {Coherent} {Line} {Stylization} for {Animated} 3D {Models}},
	abstract = {This paper presents a method for creating coherently animated line drawings that include strong abstraction and stylization effects. These effects are achieved with active strokes: 2D contours that approximate and track the lines of an animated 3D scene. Active strokes perform two functions: they connect and smooth unorganized line samples, and they carry coherent parameterization to support stylized rendering. Line samples are approximated and tracked using active contours (“snakes”) that automatically update their arrangment and topology to match the animation. Parameterization is maintained by brush paths that follow the snakes but are independent, permitting substantial shape abstraction without compromising ﬁdelity in tracking. This approach renders complex models in a wide range of styles at interactive rates, making it suitable for applications like games and interactive illustrations.},
	language = {en},
	author = {Benard, Pierre and Lu, Jingwan and Cole, Forrester and Finkelstein, Adam and Thollot, Joelle},
	year = {2012},
	pages = {11},
	file = {Benard et al. - 2012 - Active Strokes Coherent Line Stylization for Anim.pdf:/home/misnel/Zotero/storage/X5B2U5BK/Benard et al. - 2012 - Active Strokes Coherent Line Stylization for Anim.pdf:application/pdf}
}

@inproceedings{halper_opennpar:_2003,
	address = {Canmore, Alta., Canada},
	title = {{OPENNPAR}: a system for developing, programming, and designing non-photorealistic animation and rendering},
	isbn = {978-0-7695-2028-5},
	shorttitle = {{OPENNPAR}},
	url = {http://ieeexplore.ieee.org/document/1238288/},
	doi = {10.1109/PCCGA.2003.1238288},
	abstract = {The notable amount and variation of current techniques in non-photorealistic rendering (NPR) indicates a level of maturity whereby the categorization of algorithms has become possible. We present a conceptual model for NPR, on which we base a modular system, OPENNPAR, which integrates NPR algorithms into distinct classes. Components in OPENNPAR are modularized and consequently reintegrated for various rendering purposes, allowing many kinds of NPR algorithms to be reproduced, including the integration of 2D and 3D methods. Additionally, the system provides support for a range of users (developers, programmers, designers) according to their respective levels of abstraction, thus being available in multiple contexts. Ultimately, OPENNPAR holds great potential as a tool in the development, augmentation, and creation of NPR effects.},
	language = {en},
	urldate = {2019-02-13},
	booktitle = {11th {Pacific} {Conference} {onComputer} {Graphics} and {Applications}, 2003. {Proceedings}.},
	publisher = {IEEE Comput. Soc},
	author = {Halper, N. and Isenberg, T. and Ritter, F.},
	year = {2003},
	pages = {424--428},
	file = {Halper et al. - 2003 - OPENNPAR a system for developing, programming, an.pdf:/home/misnel/Zotero/storage/CW5PKTEL/Halper et al. - 2003 - OPENNPAR a system for developing, programming, an.pdf:application/pdf}
}

@article{vergne_implicit_2011,
	title = {Implicit {Brushes} for {Stylized} {Line}-based {Rendering}},
	volume = {30},
	issn = {01677055},
	url = {http://doi.wiley.com/10.1111/j.1467-8659.2011.01892.x},
	doi = {10.1111/j.1467-8659.2011.01892.x},
	abstract = {We introduce a new technique called Implicit Brushes to render animated 3D scenes with stylized lines in realtime with temporal coherence. An Implicit Brush is deﬁned at a given pixel by the convolution of a brush footprint along a feature skeleton; the skeleton itself is obtained by locating surface features in the pixel neighborhood. Features are identiﬁed via image-space ﬁtting techniques that not only extract their location, but also their proﬁle, which permits to distinguish between sharp and smooth features. Proﬁle parameters are then mapped to stylistic parameters such as brush orientation, size or opacity to give rise to a wide range of line-based styles.},
	language = {en},
	number = {2},
	urldate = {2019-02-14},
	journal = {Computer Graphics Forum},
	author = {Vergne, Romain and Vanderhaeghe, David and Chen, Jiazhou and Barla, Pascal and Granier, Xavier and Schlick, Christophe},
	month = apr,
	year = {2011},
	pages = {513--522},
	file = {Vergne et al. - 2011 - Implicit Brushes for Stylized Line-based Rendering.pdf:/home/misnel/Zotero/storage/6N2TZZNF/Vergne et al. - 2011 - Implicit Brushes for Stylized Line-based Rendering.pdf:application/pdf}
}

@inproceedings{benard_dynamic_2009,
	address = {Boston, Massachusetts},
	title = {Dynamic solid textures for real-time coherent stylization},
	isbn = {978-1-60558-429-4},
	url = {http://portal.acm.org/citation.cfm?doid=1507149.1507169},
	doi = {10.1145/1507149.1507169},
	abstract = {Stylized rendering methods, which aim at depicting 3D scenes with 2D marks such as pigments or strokes, are often faced with temporal coherence issues when applied to dynamic scenes. These issues arise from the difﬁculty of having to satisfy two contrary goals: ensuring that the style marks follow 3D motions while preserving their 2D appearance. In this paper we describe a new texture based method for real-time temporally coherent stylization called dynamic textures. A dynamic texture is a standard texture mapped on the object and enriched with an inﬁnite zoom mechanism. This simple and fast mechanism maintains quasi-constant size and density of texture elements in screen space for any distance from the camera. We show that these dynamic textures can be used in many stylization techniques, enforcing the 2D appearance of the style marks while preserving the accurate 3D motion of the depicted objects.},
	language = {en},
	urldate = {2019-03-11},
	booktitle = {Proceedings of the 2009 symposium on {Interactive} 3D graphics and games - {I}3D '09},
	publisher = {ACM Press},
	author = {Bénard, Pierre and Bousseau, Adrien and Thollot, Joëlle},
	year = {2009},
	pages = {121},
	file = {Bénard et al. - 2009 - Dynamic solid textures for real-time coherent styl.pdf:/home/misnel/Zotero/storage/3NTTGS6S/Bénard et al. - 2009 - Dynamic solid textures for real-time coherent styl.pdf:application/pdf}
}

@inproceedings{meier_painterly_1996,
	address = {Not Known},
	title = {Painterly rendering for animation},
	isbn = {978-0-89791-746-9},
	url = {http://portal.acm.org/citation.cfm?doid=237170.237288},
	doi = {10.1145/237170.237288},
	abstract = {We present a technique for rendering animations in a painterly style. The difﬁculty in using existing still frame methods for animation is getting the paint to “stick” to surfaces rather than randomly change with each frame, while still retaining a hand-crafted look. We extend the still frame method to animation by solving two major speciﬁc problems of previous techniques. First our method eliminates the “shower door” effect in which an animation appears as if it were being viewed through textured glass because brush strokes stick to the viewplane not to the animating surfaces. Second, our technique provides for frame-to-frame coherence in animations so that the resulting frames do not randomly change every frame. To maintain coherence, we model surfaces as 3d particle sets which are rendered as 2d paint brush strokes in screen space much like an artist lays down brush strokes on a canvas. We use geometric and lighting properties of the surfaces to control the appearance of brush strokes. This powerful combination of using 3d particles, surface lighting information, and rendering 2d brush strokes in screen space gives us the painterly style we desire and forces the brush strokes to stick to animating surfaces. By varying lighting and choosing brush stroke parameters we can create many varied painterly styles. We illustrate the method with images and animated sequences and present speciﬁc technical and creative suggestions for achieving different looks.},
	language = {en},
	urldate = {2019-03-29},
	booktitle = {Proceedings of the 23rd annual conference on {Computer} graphics and interactive techniques  - {SIGGRAPH} '96},
	publisher = {ACM Press},
	author = {Meier, Barbara J.},
	year = {1996},
	pages = {477--484},
	file = {Meier - 1996 - Painterly rendering for animation.pdf:/home/misnel/Zotero/storage/GU66Z3V8/Meier - 1996 - Painterly rendering for animation.pdf:application/pdf}
}

@article{lin_video_nodate,
	title = {Video {Stylization}: {Painterly} {Rendering} and {Optimization} with {Content} {Extraction}},
	abstract = {We present an interactive video stylization system for transforming an input video into a painterly animation. The system consists of two phases: a content extraction phase to obtain semantic objects, i.e. recognized content, in a video and establish dense feature correspondences; and a painterly rendering phase to select, place and propagate brush strokes for stylized animations based on the semantic content and object motions derived from the ﬁrst phase. Compared with the previous work, the proposed method has the following three advantages: Firstly, we propose a two-pass rendering strategy and brush strokes with mixed colors in order to render expressive visual effects. Secondly, the brush strokes are warped according to global object deformations, so that the strokes appear to be naturally attached to the object surfaces. Thirdly, we propose a deferred rendering and backward completion method to draw brush strokes on emerging regions, and simulate a damped system to reduce stroke scintillation effect. Moreover, we discuss the GPU-based implementation of our system, which is demonstrated to greatly improve the efﬁciency of producing stylized videos. In experiments, we verify this system by applying it to a number of video clips to produce expressive oil-painting animations and compare with the state-of-the-arts approaches.},
	language = {en},
	journal = {IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS FOR VIDEO TECHNOLOGY},
	author = {Lin, Liang and Zeng, Kun and Wang, Yizhou and Xu, Ying-Qing and Zhu, Song-Chun},
	pages = {13},
	file = {Lin et al. - Video Stylization Painterly Rendering and Optimiz.pdf:/home/misnel/Zotero/storage/VZLKWL4T/Lin et al. - Video Stylization Painterly Rendering and Optimiz.pdf:application/pdf}
}

@inproceedings{bezerra_image-based_2005,
	address = {Natal, Rio Grande do Norte, Brazil},
	title = {An {Image}-{Based} {Shading} {Pipeline} for 2D {Animation}},
	isbn = {978-0-7695-2389-7},
	url = {http://ieeexplore.ieee.org/document/1599118/},
	doi = {10.1109/SIBGRAPI.2005.9},
	abstract = {Shading for cel animation based on images is a recent research topic in computer-assisted animation. This paper proposes an image-based shading pipeline to give a 3D appearance to a 2D character by inspecting the hand-drawn image directly. The proposed method estimates normal vectors on the character’s outline and interpolates them over the remaining image. The method does not limit the animator’s creative process and requires minimal user intervention. The resulting shading pipeline can be easily applied to photorealistic and non-photorealistic 2D cel animation. In the proposed method, the animator can easily simulate environment reﬂections on the surface of 2D reﬂecting objects. As far as the authors are concerned, the proposed technique is the only one in the literature that is genuinely an image-based method for 2D animation.},
	language = {en},
	urldate = {2019-04-08},
	booktitle = {{XVIII} {Brazilian} {Symposium} on {Computer} {Graphics} and {Image} {Processing} ({SIBGRAPI}'05)},
	publisher = {IEEE},
	author = {Bezerra, H. and Feijo, B. and Velho, L.},
	year = {2005},
	pages = {307--314},
	file = {Bezerra et al. - 2005 - An Image-Based Shading Pipeline for 2D Animation.pdf:/home/misnel/Zotero/storage/PRQLAMHK/Bezerra et al. - 2005 - An Image-Based Shading Pipeline for 2D Animation.pdf:application/pdf}
}

@inproceedings{imhof_fin_2015,
	address = {Paris, France},
	title = {Fin textures for real-time painterly aesthetics},
	isbn = {978-1-4503-3991-9},
	url = {http://dl.acm.org/citation.cfm?doid=2822013.2822021},
	doi = {10.1145/2822013.2822021},
	language = {en},
	urldate = {2019-04-08},
	booktitle = {Proceedings of the 8th {ACM} {SIGGRAPH} {Conference} on {Motion} in {Games} - {SA} '15},
	publisher = {ACM Press},
	author = {Imhof, Nicolas and Milliez, Antoine and Jenal, Flurin and Bauer, René and Gross, Markus and Sumner, Robert W.},
	year = {2015},
	pages = {227--235},
	file = {Imhof et al. - 2015 - Fin textures for real-time painterly aesthetics.pdf:/home/misnel/Zotero/storage/N8JV4Z8S/Imhof et al. - 2015 - Fin textures for real-time painterly aesthetics.pdf:application/pdf}
}

@article{kyprianidis_state_2013,
	title = {State of the "{Art}”: {A} {Taxonomy} of {Artistic} {Stylization} {Techniques} for {Images} and {Video}},
	volume = {19},
	issn = {1077-2626},
	shorttitle = {State of the "{Art}”},
	doi = {10.1109/TVCG.2012.160},
	abstract = {This paper surveys the field of nonphotorealistic rendering (NPR), focusing on techniques for transforming 2D input (images and video) into artistically stylized renderings. We first present a taxonomy of the 2D NPR algorithms developed over the past two decades, structured according to the design characteristics and behavior of each technique. We then describe a chronology of development from the semiautomatic paint systems of the early nineties, through to the automated painterly rendering systems of the late nineties driven by image gradient analysis. Two complementary trends in the NPR literature are then addressed, with reference to our taxonomy. First, the fusion of higher level computer vision and NPR, illustrating the trends toward scene analysis to drive artistic abstraction and diversity of style. Second, the evolution of local processing approaches toward edge-aware filtering for real-time stylization of images and video. The survey then concludes with a discussion of open challenges for 2D NPR identified in recent NPR symposia, including topics such as user and aesthetic evaluation.},
	number = {5},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Kyprianidis, J. E. and Collomosse, J. and Wang, T. and Isenberg, T.},
	month = may,
	year = {2013},
	keywords = {2D NPR algorithms, aesthetic evaluation, Algorithm design and analysis, art, artistic abstraction, artistic rendering, artistic stylization techniques, artistically stylized renderings, automated painterly rendering systems, Computer Graphics, computer vision, Creativity, design characteristics, edge-aware filtering, filtering theory, Forecasting, gradient methods, Image and video stylization, Image color analysis, Image edge detection, image gradient analysis, Imaging, Three-Dimensional, nonphotorealistic rendering, nonphotorealistic rendering (NPR), NPR literature, NPR symposia, Painting, Paintings, real-time stylization, real-time systems, rendering (computer graphics), Rendering (computer graphics), scene analysis, semiautomatic paint systems, taxonomy, Taxonomy, user evaluation, User-Computer Interface, Video Recording, video signal processing},
	pages = {866--885},
	file = {IEEE Xplore Abstract Record:/home/misnel/Zotero/storage/VCJSCFYL/6243138.html:text/html;IEEE Xplore Full Text PDF:/home/misnel/Zotero/storage/PLGSX8R8/Kyprianidis et al. - 2013 - State of the Art” A Taxonomy of Artistic Styliza.pdf:application/pdf}
}

@article{belhadj_consistent_nodate,
	title = {Consistent {Media} {Model} for {Real}-{Time} {Scene} {Rendering}},
	abstract = {We present a consistent model for artistic media reproduction in 3D scene renderings and animations. Artistic media reproduction can be deﬁned as a media model (such as brush, pencil, ink) and a support (such as canvas and papers). We create a surface grain according to the object geometry and apply it as additional material properties. Furthermore, we propose to use the abstraction of obtained results as an entry of a fractal surface reconstruction process that provides additional effects of traditional media such as brush stroke effects. Our model is fully implemented on GPU and the rendering process is strongly real-time.},
	language = {en},
	author = {Belhadj, Farès and Suarez, Jordane and Boyer, Vincent},
	pages = {2},
	file = {Belhadj et al. - Consistent Media Model for Real-Time Scene Renderi.pdf:/home/misnel/Zotero/storage/YH5DU46K/Belhadj et al. - Consistent Media Model for Real-Time Scene Renderi.pdf:application/pdf}
}

@article{khlebnikov_procedural_2012,
	title = {Procedural {Texture} {Synthesis} for {Zoom}-{Independent} {Visualization} of {Multivariate} {Data}},
	volume = {31},
	issn = {01677055},
	url = {http://doi.wiley.com/10.1111/j.1467-8659.2012.03127.x},
	doi = {10.1111/j.1467-8659.2012.03127.x},
	abstract = {Simultaneous visualization of multiple continuous data attributes in a single visualization is a task that is important for many application areas. Unsurprisingly, many methods have been proposed to solve this task. However, the behavior of such methods during the exploration stage, when the user tries to understand the data with panning and zooming, has not been given much attention.},
	language = {en},
	number = {3pt4},
	urldate = {2019-04-08},
	journal = {Computer Graphics Forum},
	author = {Khlebnikov, R. and Kainz, B. and Steinberger, M. and Streit, M. and Schmalstieg, D.},
	month = jun,
	year = {2012},
	pages = {1355--1364},
	file = {Khlebnikov et al. - 2012 - Procedural Texture Synthesis for Zoom-Independent .pdf:/home/misnel/Zotero/storage/475A9F9R/Khlebnikov et al. - 2012 - Procedural Texture Synthesis for Zoom-Independent .pdf:application/pdf}
}

@article{scherzer_temporal_2012,
	title = {Temporal {Coherence} {Methods} in {Real}-{Time} {Rendering}},
	volume = {31},
	issn = {01677055},
	url = {http://doi.wiley.com/10.1111/j.1467-8659.2012.03075.x},
	doi = {10.1111/j.1467-8659.2012.03075.x},
	abstract = {Nowadays, there is a strong trend towards rendering to higher-resolution displays and at high frame rates. This development aims at delivering more detail and better accuracy, but it also comes at a signiﬁcant cost. Although graphics cards continue to evolve with an ever-increasing amount of computational power, the speed gain is easily counteracted by increasingly complex and sophisticated shading computations. For real-time applications, the direct consequence is that image resolution and temporal resolution are often the ﬁrst candidates to bow to the performance constraints (e.g. although full HD is possible, PS3 and XBox often render at lower resolutions).},
	language = {en},
	number = {8},
	urldate = {2019-04-08},
	journal = {Computer Graphics Forum},
	author = {Scherzer, Daniel and Yang, Lei and Mattausch, Oliver and Nehab, Diego and Sander, Pedro V. and Wimmer, Michael and Eisemann, Elmar},
	month = dec,
	year = {2012},
	pages = {2378--2408},
	file = {Scherzer et al. - 2012 - Temporal Coherence Methods in Real-Time Rendering.pdf:/home/misnel/Zotero/storage/9LMEPFQG/Scherzer et al. - 2012 - Temporal Coherence Methods in Real-Time Rendering.pdf:application/pdf}
}

@article{zeng_image_2009,
	title = {From image parsing to painterly rendering},
	volume = {29},
	issn = {07300301},
	url = {http://portal.acm.org/citation.cfm?doid=1640443.1640445},
	doi = {10.1145/1640443.1640445},
	language = {en},
	number = {1},
	urldate = {2019-04-08},
	journal = {ACM Transactions on Graphics},
	author = {Zeng, Kun and Zhao, Mingtian and Xiong, Caiming and Zhu, Song-Chun},
	month = dec,
	year = {2009},
	pages = {1--11},
	file = {Zeng et al. - 2009 - From image parsing to painterly rendering.pdf:/home/misnel/Zotero/storage/VD4FA9BF/Zeng et al. - 2009 - From image parsing to painterly rendering.pdf:application/pdf}
}

@article{lagae_procedural_2009,
	title = {Procedural noise using sparse {Gabor} convolution},
	volume = {28},
	issn = {07300301},
	url = {http://portal.acm.org/citation.cfm?doid=1531326.1531360},
	doi = {10.1145/1531326.1531360},
	abstract = {Noise is an essential tool for texturing and modeling. Designing interesting textures with noise calls for accurate spectral control, since noise is best described in terms of spectral content. Texturing requires that noise can be easily mapped to a surface, while high-quality rendering requires anisotropic ﬁltering. A noise function that is procedural and fast to evaluate offers several additional advantages. Unfortunately, no existing noise combines all of these properties.},
	language = {en},
	number = {3},
	urldate = {2019-04-08},
	journal = {ACM Transactions on Graphics},
	author = {Lagae, Ares and Lefebvre, Sylvain and Drettakis, George and Dutré, Philip},
	month = jul,
	year = {2009},
	pages = {1},
	file = {Lagae et al. - 2009 - Procedural noise using sparse Gabor convolution.pdf:/home/misnel/Zotero/storage/GTT7LFRG/Lagae et al. - 2009 - Procedural noise using sparse Gabor convolution.pdf:application/pdf}
}

@article{benard_quality_nodate,
	title = {Quality assessment of fractalized {NPR} textures: a perceptual objective metric},
	abstract = {Texture fractalization is used in many existing approaches to ensure the temporal coherence of a stylized animation. This paper presents the results of a psychological user-study evaluating the relative distortion induced by a fractalization process of typical medium textures. We perform a ranking experiment, assess the agreement among the participant and study the criteria they used. Finally we show that the average co-occurrence error is an efﬁcient quality predictor in this context.},
	language = {en},
	author = {Benard, Pierre and Thollot, Joelle and Sillion, Francois},
	pages = {4},
	file = {Benard et al. - Quality assessment of fractalized NPR textures a .pdf:/home/misnel/Zotero/storage/77INDG9U/Benard et al. - Quality assessment of fractalized NPR textures a .pdf:application/pdf}
}

@article{breslav_dynamic_nodate,
	title = {Dynamic 2D {Patterns} for {Shading} 3D {Scenes}},
	abstract = {We describe a new way to render 3D scenes in a variety of nonphotorealistic styles, based on patterns whose structure and motion are deﬁned in 2D. In doing so, we sacriﬁce the ability of patterns that wrap onto 3D surfaces to convey shape through their structure and motion. In return, we gain several advantages, chieﬂy that 2D patterns are more visually abstract – a quality often sought by artists, which explains their widespread use in hand-drawn images.},
	language = {en},
	author = {Breslav, Simon and Szerszen, Karol and Markosian, Lee and Barla, Pascal and Thollot, Joëlle},
	pages = {6},
	file = {Breslav et al. - Dynamic 2D Patterns for Shading 3D Scenes.pdf:/home/misnel/Zotero/storage/M5WH7WP2/Breslav et al. - Dynamic 2D Patterns for Shading 3D Scenes.pdf:application/pdf}
}

@article{bousseau_video_2007,
	title = {Video watercolorization using bidirectional texture advection},
	volume = {26},
	issn = {07300301},
	url = {http://portal.acm.org/citation.cfm?doid=1276377.1276507},
	doi = {10.1145/1276377.1276507},
	abstract = {In this paper, we present a method for creating watercolor-like animation, starting from video as input. The method involves two main steps: applying textures that simulate a watercolor appearance; and creating a simpliﬁed, abstracted version of the video to which the texturing operations are applied. Both of these steps are subject to highly visible temporal artifacts, so the primary technical contributions of the paper are extensions of previous methods for texturing and abstraction to provide temporal coherence when applied to video sequences. To maintain coherence for textures, we employ texture advection along lines of optical ﬂow. We furthermore extend previous approaches by incorporating advection in both forward and reverse directions through the video, which allows for minimal texture distortion, particularly in areas of disocclusion that are otherwise highly problematic. To maintain coherence for abstraction, we employ mathematical morphology extended to the temporal domain, using ﬁlters whose temporal extents are locally controlled by the degree of distortions in the optical ﬂow. Together, these techniques provide the ﬁrst practical and robust approach for producing watercolor animations from video, which we demonstrate with a number of examples.},
	language = {en},
	number = {3},
	urldate = {2019-04-08},
	journal = {ACM Transactions on Graphics},
	author = {Bousseau, Adrien and Neyret, Fabrice and Thollot, Joëlle and Salesin, David},
	month = jul,
	year = {2007},
	pages = {104},
	file = {Bousseau et al. - 2007 - Video watercolorization using bidirectional textur.pdf:/home/misnel/Zotero/storage/J9IQMQYB/Bousseau et al. - 2007 - Video watercolorization using bidirectional textur.pdf:application/pdf}
}

@inproceedings{bousseau_interactive_2006,
	address = {Annecy, France},
	title = {Interactive watercolor rendering with temporal coherence and abstraction},
	isbn = {978-1-59593-357-7},
	url = {http://portal.acm.org/citation.cfm?doid=1124728.1124751},
	doi = {10.1145/1124728.1124751},
	abstract = {This paper presents an interactive watercolor rendering technique that recreates the speciﬁc visual effects of lavis watercolor. Our method allows the user to easily process images and 3d models and is organized in two steps: an abstraction step that recreates the uniform color regions of watercolor and an effect step that ﬁlters the resulting abstracted image to obtain watercolor-like images. In the case of 3d environments we also propose two methods to produce temporally coherent animations that keep a uniform pigment repartition while avoiding the shower door effect.},
	language = {en},
	urldate = {2019-04-08},
	booktitle = {Proceedings of the 3rd international symposium on {Non}-photorealistic animation and rendering  - {NPAR} '06},
	publisher = {ACM Press},
	author = {Bousseau, Adrien and Kaplan, Matt and Thollot, Joëlle and Sillion, François X.},
	year = {2006},
	pages = {141},
	file = {Bousseau et al. - 2006 - Interactive watercolor rendering with temporal coh.pdf:/home/misnel/Zotero/storage/7L5XTCUD/Bousseau et al. - 2006 - Interactive watercolor rendering with temporal coh.pdf:application/pdf}
}

@inproceedings{hays_image_2004,
	address = {Annecy, France},
	title = {Image and video based painterly animation},
	isbn = {978-1-58113-887-0},
	url = {http://portal.acm.org/citation.cfm?doid=987657.987676},
	doi = {10.1145/987657.987676},
	abstract = {We present techniques for transforming images and videos into painterly animations depicting different artistic styles. Our techniques rely on image and video analysis to compute appearance and motion properties. We also determine and apply motion information from different (user-speciﬁed) sources to static and moving images. These properties that encode spatio-temporal variations are then used to render (or paint) effects of selected styles to generate images and videos with a painted look. Painterly animations are generated using a mesh of brush stroke objects with dynamic spatio-temporal properties. Styles govern the behavior of these brush strokes as well as their rendering to a virtual canvas. We present methods for modifying the properties of these brush strokes according to the input images, videos, or motions. Brush stroke color, length, orientation, opacity, and motion are determined and the brush strokes are regenerated to ﬁll the canvas as the video changes. All brush stroke properties are temporally constrained to guarantee temporally coherent non-photorealistic animations.},
	language = {en},
	urldate = {2019-04-08},
	booktitle = {Proceedings of the 3rd international symposium on {Non}-photorealistic animation and rendering  - {NPAR} '04},
	publisher = {ACM Press},
	author = {Hays, James and Essa, Irfan},
	year = {2004},
	pages = {113},
	file = {Hays et Essa - 2004 - Image and video based painterly animation.pdf:/home/misnel/Zotero/storage/GZPGUWE5/Hays et Essa - 2004 - Image and video based painterly animation.pdf:application/pdf}
}

@article{fung_pen-and-ink_nodate,
	title = {"{Pen}-and-ink textures for real-time rendering"},
	abstract = {Simulation of a pen-and-ink illustration style in a realtime rendering system is a challenging computer graphics problem. Tonal art maps (TAMs) were recently suggested as a solution to this problem. Unfortunately, only the hatching aspect of pen-and-ink media was addressed thus far. We extend the TAM approach and enable representation of arbitrary textures. We generate TAM images by distributing stroke primitives according to a probability density function. This function is derived from the input image and varies depending on the TAM’s scale and tone levels. The resulting depiction of textures approximates various styles of pen-and-ink illustrations such as outlining, stippling, and hatching.},
	language = {en},
	author = {Fung, Jennifer and Veryovka, Oleg},
	pages = {6},
	file = {Fung et Veryovka - Pen-and-ink textures for real-time rendering.pdf:/home/misnel/Zotero/storage/PLNZZFHS/Fung et Veryovka - Pen-and-ink textures for real-time rendering.pdf:application/pdf}
}

@article{kalnins_wysiwyg_nodate,
	title = {{WYSIWYG} {NPR}: {Drawing} {Strokes} {Directly} on 3D {Models}},
	abstract = {We present a system that lets a designer directly annotate a 3D model with strokes, imparting a personal aesthetic to the non-photorealistic rendering of the object. The artist chooses a “brush” style, then draws strokes over the model from one or more viewpoints. When the system renders the scene from any new viewpoint, it adapts the number and placement of the strokes appropriately to maintain the original look.},
	language = {en},
	author = {Kalnins, Robert D and Markosian, Lee and Meier, Barbara J and Kowalski, Michael A and Lee, Joseph C and Davidson, Philip L and Webb, Matthew and Hughes, John F and Finkelstein, Adam},
	pages = {8},
	file = {Kalnins et al. - WYSIWYG NPR Drawing Strokes Directly on 3D Models.pdf:/home/misnel/Zotero/storage/VIYM2GK5/Kalnins et al. - WYSIWYG NPR Drawing Strokes Directly on 3D Models.pdf:application/pdf}
}

@inproceedings{litwinowicz_processing_1997,
	address = {Not Known},
	title = {Processing images and video for an impressionist effect},
	isbn = {978-0-89791-896-1},
	url = {http://portal.acm.org/citation.cfm?doid=258734.258893},
	doi = {10.1145/258734.258893},
	abstract = {This paper describes a technique that transforms ordinary video segments into animations that have a hand-painted look. Our method is the first to exploit temporal coherence in video clips to design an automatic filter with a hand-drawn animation quality, in this case, one that produces an Impressionist effect. Off-the-shelf image processing and rendering techniques are employed, modified and combined in a novel way. This paper proceeds through the process step by step, providing helpful hints for tuning the off-the-shelf parts as well as describing the new techniques and bookkeeping used to glue the parts together.},
	language = {en},
	urldate = {2019-04-08},
	booktitle = {Proceedings of the 24th annual conference on {Computer} graphics and interactive techniques  - {SIGGRAPH} '97},
	publisher = {ACM Press},
	author = {Litwinowicz, Peter},
	year = {1997},
	pages = {407--414},
	file = {Litwinowicz - 1997 - Processing images and video for an impressionist e.pdf:/home/misnel/Zotero/storage/AS62S7B5/Litwinowicz - 1997 - Processing images and video for an impressionist e.pdf:application/pdf}
}

@article{benard_dynamic_2010,
	title = {A {Dynamic} {Noise} {Primitive} for {Coherent} {Stylization}},
	volume = {29},
	issn = {01677055},
	url = {http://doi.wiley.com/10.1111/j.1467-8659.2010.01747.x},
	doi = {10.1111/j.1467-8659.2010.01747.x},
	abstract = {We present a new solution for temporal coherence in non-photorealistic rendering (NPR) of animations. Given the conﬂicting goals of preserving the 2D aspect of the style and the 3D scene motion, any such solution is a tradeoff. We observe that primitive-based methods in NPR can be seen as texture-based methods when using large numbers of primitives, leading to our key insight, namely that this process is similar to sparse convolution noise in procedural texturing. Consequently, we present a new primitive for NPR based on Gabor noise, that preserves the 2D aspect of noise, conveys the 3D motion of the scene, and is temporally continuous. We can thus use standard techniques from procedural texturing to create various styles, which we show for interactive NPR applications. We also present a user study to evaluate this and existing solutions, and to provide more insight in the trade-off implied by temporal coherence. The results of the study indicate that maintaining coherent motion is important, but also that our new solution provides a good compromise between the 2D aspect of the style and 3D motion.},
	language = {en},
	number = {4},
	urldate = {2019-04-08},
	journal = {Computer Graphics Forum},
	author = {Bénard, P. and Lagae, A. and Vangorp, P. and Lefebvre, S. and Drettakis, G. and Thollot, J.},
	month = aug,
	year = {2010},
	pages = {1497--1506},
	file = {Bénard et al. - 2010 - A Dynamic Noise Primitive for Coherent Stylization.pdf:/home/misnel/Zotero/storage/GYD476ZD/Bénard et al. - 2010 - A Dynamic Noise Primitive for Coherent Stylization.pdf:application/pdf}
}

@article{wang_real-time_2010,
	title = {Real-time coherent stylization for augmented reality},
	volume = {26},
	issn = {0178-2789, 1432-2315},
	url = {http://link.springer.com/10.1007/s00371-010-0436-z},
	doi = {10.1007/s00371-010-0436-z},
	language = {en},
	number = {6-8},
	urldate = {2019-04-08},
	journal = {The Visual Computer},
	author = {Wang, Shandong and Cai, Kangying and Lu, Jian and Liu, Xuehui and Wu, Enhua},
	month = jun,
	year = {2010},
	pages = {445--455},
	file = {Wang et al. - 2010 - Real-time coherent stylization for augmented reali.pdf:/home/misnel/Zotero/storage/5C7CUELS/Wang et al. - 2010 - Real-time coherent stylization for augmented reali.pdf:application/pdf}
}

@article{grabli_programmable_2010,
	title = {Programmable rendering of line drawing from 3D scenes},
	volume = {29},
	issn = {07300301},
	url = {http://portal.acm.org/citation.cfm?doid=1731047.1731056},
	doi = {10.1145/1731047.1731056},
	language = {en},
	number = {2},
	urldate = {2019-04-08},
	journal = {ACM Transactions on Graphics},
	author = {Grabli, Stéphane and Turquin, Emmanuel and Durand, Frédo and Sillion, François X.},
	month = mar,
	year = {2010},
	pages = {1--20},
	file = {Grabli et al. - 2010 - Programmable rendering of line drawing from 3D sce.pdf:/home/misnel/Zotero/storage/VNG8F3HI/Grabli et al. - 2010 - Programmable rendering of line drawing from 3D sce.pdf:application/pdf}
}

@inproceedings{kass_coherent_2011,
	address = {Vancouver, British Columbia, Canada},
	title = {Coherent noise for non-photorealistic rendering},
	isbn = {978-1-4503-0943-1},
	url = {http://portal.acm.org/citation.cfm?doid=1964921.1964925},
	doi = {10.1145/1964921.1964925},
	abstract = {A wide variety of non-photorealistic rendering techniques make use of random variation in the placement or appearance of primitives. In order to avoid the “shower-door” effect, this random variation should move with the objects in the scene. Here we present coherent noise tailored to this purpose. We compute the coherent noise with a specialized ﬁlter that uses the depth and velocity ﬁelds of a source sequence. The computation is fast and suitable for interactive applications like games.},
	language = {en},
	urldate = {2019-04-09},
	booktitle = {{ACM} {SIGGRAPH} 2011 papers on - {SIGGRAPH} '11},
	publisher = {ACM Press},
	author = {Kass, Michael and Pesare, Davide},
	year = {2011},
	pages = {1},
	file = {Kass et Pesare - 2011 - Coherent noise for non-photorealistic rendering.pdf:/home/misnel/Zotero/storage/E8R5WDBR/Kass et Pesare - 2011 - Coherent noise for non-photorealistic rendering.pdf:application/pdf}
}

@article{cunzi_dynamic_nodate,
	title = {Dynamic {Canvas} for {Non}-{Photorealistic} {Walkthroughs}},
	abstract = {The static background paper or canvas texture usually used for non-photorealistic animation greatly impedes the sensation of motion and results in a disturbing “shower door” effect. We present a method to animate the background canvas for non-photorealistic rendering animations and walkthroughs, which greatly improves the sensation of motion and 3D “immersion”. The complex motion ﬁeld induced by the 3D displacement is matched using purely 2D transformations. The motion ﬁeld of forward translations is approximated using a 2D zoom in the texture, and camera rotation is approximated using 2D translation and rotation. A rolling-ball metaphor is introduced to match the instantaneous 3D motion with a 2D transformation. An inﬁnite zoom in the texture is made possible by using a paper model based on multifrequency solid turbulence. Our results indicate a dramatic improvement over a static background.},
	language = {en},
	author = {Cunzi, Matthieu and Thollot, Joelle and Gascuel, Jean-Dominique and Paris, Sylvain and Debunne, Gilles},
	pages = {10},
	file = {Cunzi et al. - Dynamic Canvas for Non-Photorealistic Walkthroughs.pdf:/home/misnel/Zotero/storage/BFQR9VGC/Cunzi et al. - Dynamic Canvas for Non-Photorealistic Walkthroughs.pdf:application/pdf}
}

@incollection{rosin_stroke_2013,
	address = {London},
	title = {Stroke {Based} {Painterly} {Rendering}},
	volume = {42},
	isbn = {978-1-4471-4518-9 978-1-4471-4519-6},
	url = {http://link.springer.com/10.1007/978-1-4471-4519-6_1},
	abstract = {Many traditional art forms are produced by an artist sequentially placing a set of marks, such as brush strokes, on a canvas. Stroke based Rendering (SBR) is inspired by this process, and underpins many early and contemporary Artistic Stylization algorithms. This Chapter outlines the origins of SBR, and describes key algorithms for placement of brush strokes to create painterly renderings from source images. The chapter explores both local greedy, and global optimization based approaches to stroke placement. The issue of creative control in SBR is also brieﬂy discussed.},
	language = {en},
	urldate = {2019-04-11},
	booktitle = {Image and {Video}-{Based} {Artistic} {Stylisation}},
	publisher = {Springer London},
	author = {Vanderhaeghe, David and Collomosse, John},
	editor = {Rosin, Paul and Collomosse, John},
	year = {2013},
	doi = {10.1007/978-1-4471-4519-6_1},
	pages = {3--21},
	file = {Vanderhaeghe et Collomosse - 2013 - Stroke Based Painterly Rendering.pdf:/home/misnel/Zotero/storage/5Q65UWYT/Vanderhaeghe et Collomosse - 2013 - Stroke Based Painterly Rendering.pdf:application/pdf}
}